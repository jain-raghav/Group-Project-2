---
title: "Dataset Exploration"
author: "Malik Abbasi, Raghav Jain, Himansu Vepamakula, Ari Bosse"
date: "11/2/2021"
output:
  html_document:
    code_folding: show
    toc: true
    toc_float:
      toc_collapsed: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Data Cleaning and Organization
```{r}
library(caret)
cdata <- read.csv("WA_Fn-UseC_-Telco-Customer-Churn.csv", stringsAsFactors = TRUE)

#Removes rows with any NA values -- Should not affect results as there is a total of 7500+ rows of data and only 11 rows are removed
cdata <- na.omit(cdata)


#upsample dataset to have equal observations for churn outcomes
cdata <- upSample(cdata, as.factor(cdata$Churn))

#Removing CustomerID from dataset as it is not predictive
cdata$customerID <- NULL
cdata$Class <- NULL

#replace "no phone/internet service" with no to limit numbers of factors
cdata$OnlineSecurity <- as.factor(ifelse(cdata$OnlineSecurity == "No internet service" | cdata$OnlineSecurity == "No", "No", "Yes"))
cdata$OnlineBackup <- as.factor(ifelse(cdata$OnlineBackup == "No internet service" | cdata$OnlineBackup == "No", "No", "Yes"))
cdata$DeviceProtection <- as.factor(ifelse(cdata$DeviceProtection == "No internet service" | cdata$DeviceProtection == "No", "No", "Yes"))
cdata$TechSupport <- as.factor(ifelse(cdata$TechSupport == "No internet service" | cdata$TechSupport == "No", "No", "Yes"))
cdata$StreamingTV <- as.factor(ifelse(cdata$StreamingTV == "No internet service" | cdata$StreamingTV == "No", "No", "Yes"))
cdata$StreamingMovies <- as.factor(ifelse(cdata$StreamingMovies == "No internet service" | cdata$StreamingMovies == "No", "No", "Yes"))
cdata$MultipleLines <- as.factor(ifelse(cdata$MultipleLines == "No phone service" | cdata$MultipleLines == "No", "No", "Yes"))

cdata$NumServices <- as.numeric(cdata$PhoneService == "Yes") + as.numeric(cdata$MultipleLines == "Yes") + as.numeric(cdata$InternetService != "No") + as.numeric(cdata$OnlineSecurity == "Yes") + as.numeric(cdata$OnlineBackup == "Yes") + as.numeric(cdata$DeviceProtection == "Yes") + as.numeric(cdata$TechSupport == "Yes") + as.numeric(cdata$StreamingTV == "Yes") + as.numeric(cdata$StreamingMovies == "Yes")

str(cdata)
summary(cdata)

cdataMatrix <- as.data.frame(model.matrix(~.-1,cdata))

#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# we are going to normalize everything 
cdataMatrix <- as.data.frame(lapply(cdataMatrix, normalize))
###
###

#creating test and train set
set.seed(12345)
test_set <- sample(1:nrow(cdata), round(nrow(cdata) / 2,0))

c_train <- cdata[-test_set, -match("Churn",names(cdata))]
c_test <- cdata[test_set, -match("Churn",names(cdata))]
c_trainMatrix <- cdataMatrix[-test_set, -match("ChurnYes",names(cdataMatrix))]
c_testMatrix <- cdataMatrix[test_set, -match("ChurnYes",names(cdataMatrix))]

#labels for the response variable 

c_train_labels <- cdata[-test_set, "Churn"]
c_test_labels <- cdata[test_set, "Churn"]
c_train_labelsMatrix <- cdataMatrix[-test_set, "ChurnYes"]
c_test_labelsMatrix <- cdataMatrix[test_set, "ChurnYes"]
```

### Data Visualization

```{r}
library(ggplot2)
library(dplyr)

#Exploring Gender and Senior Citizens
cdata %>% ggplot(.) + geom_histogram(aes(x = gender, fill = gender), stat = "count") + ggtitle("Customer Genders") + xlab("Gender") + ylab("Count")

cdata %>% group_by(Churn,gender) %>% summarise(count = n()) %>% ggplot(.) + geom_col(aes(x=Churn, y = count, fill = gender)) + xlab("Churn") + ylab("Count") 

cdata %>% ggplot(.) + geom_histogram(aes(x=ifelse(as.factor(SeniorCitizen) == 1, "Yes", "No"), fill = gender),  stat = "count") + ggtitle("Senior Citizen Customers") + xlab("Senior Citizen Status") + ylab("Count")
```

```{r}
#Exploring Tenure
cdata %>% ggplot(.)  + geom_density(aes(tenure,group=gender, fill=gender, colour=gender), alpha=0.15) + ggtitle("Distribution of tenure per gender") + xlab("Tenure (in months)")

cdata %>% ggplot(.) + geom_histogram(aes(x = tenure, fill = gender)) + ggtitle("Tenure length, filled by gender") + xlab("Tenure (in months)")

cdata %>% ggplot(.) + geom_boxplot(aes(x = as.factor(SeniorCitizen), y = tenure, fill = gender)) + xlab("Senior Citizen Status") + ylab("Tenure (in months)")

cdata %>% ggplot(.) + geom_boxplot(aes(x = Churn, y = tenure, fill= gender))

#Exploring Contract Types
cdata %>% ggplot(.) + geom_histogram(aes(x = Contract, fill = gender), stat = "count") + ggtitle("Contract types, filled by gender") + xlab("Contract Type") + ylab("Number of Customers")

cdata %>% group_by(Contract) %>% summarise(avg = mean(MonthlyCharges)) %>% ggplot(.) + geom_col(aes(x=Contract, y = avg)) + xlab("Contract Type") + ylab("Average Monthly Charge") + ggtitle("Average Monthly cost per Contract")

cdata %>% ggplot(.) + geom_boxplot(aes(x = Churn, y = MonthlyCharges, fill = gender)) + ggtitle("Churn by Monthly Charges")

#Exploring Number of Services

services <- c("Total", "Phone", "Multiple Phones", "Internet", "Online Security", "Online Backup", "Device Protection", "Tech Support", "Streaming TV", "Streaming Movies")

counts <- c(nrow(cdata[,]), nrow(cdata[cdata$PhoneService == "Yes", ]), nrow(cdata[cdata$MultipleLines == "Yes", ]), nrow(cdata[cdata$InternetService != "No", ]),nrow(cdata[cdata$OnlineSecurity == "Yes", ]),nrow(cdata[cdata$OnlineBackup == "Yes", ]),nrow(cdata[cdata$DeviceProtection == "Yes", ]),nrow(cdata[cdata$TechSupport == "Yes", ]),nrow(cdata[cdata$StreamingTV == "Yes", ]),nrow(cdata[cdata$StreamingMovies == "Yes", ]))

countserv <- data.frame(services, counts)
countserv$services  <- with(countserv, reorder(services, -counts))

countserv %>% ggplot(.) + geom_col(aes(x=services, y = counts, fill = services)) + xlab("Services") + ylab("Count of Purchasing Customers") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + ggtitle("Services Purchased")

cdata %>% group_by(Contract) %>% summarise(avg = mean(NumServices)) %>% ggplot(.) + geom_col(aes(x=Contract, y = avg)) + xlab("Contract Type") + ylab("Average Number of Services") + ggtitle("Number of Services")

cdata %>% group_by(NumServices) %>% summarise(avg = mean(MonthlyCharges)) %>% ggplot(.) + geom_col(aes(x=NumServices, y = avg)) + xlab("Number of Services") + ylab("Average Monthly Charge") 

cdata %>% ggplot(.) + geom_boxplot(aes(x = as.factor(Churn), y = NumServices)) + xlab("Churn") + ylab("Number of Services") + ggtitle("Churn by number of services purchased")

```


### Logistic Regression Model
```{r}
library(caret)
#first model
c_train_labels_numeric <- ifelse(c_train_labels == "Yes", 1, 0)
c_test_labels_numeric <- ifelse(c_test_labels == "Yes", 1, 0)

glm1 <- glm(c_train_labels_numeric ~ ., data = c_train, family = binomial)
summary(glm1)

#Optimizing logistic regression
glm2 <- step(glm1, direction = "backward")

#Looking at model
summary(glm2)

#Predicting based off of model
prediction <- predict(glm2, c_test, type = "response")
prediction2 <- as.factor(ifelse(prediction > 0.5, 1, 0))

#Creating confusion matrix
glmmatrix <- confusionMatrix(prediction2, as.factor(c_test_labels_numeric))
```

### KNN Model
```{r}
library(class)
library(caret)
knn1 <- knn(train = c_trainMatrix, test = c_testMatrix, cl = c_train_labelsMatrix, k = sqrt(nrow(c_trainMatrix)))

library(gmodels)
CrossTable(x = c_train_labelsMatrix, y = knn1, prop.chisq=FALSE)

knnmatrix <- confusionMatrix(knn1, as.factor(c_test_labelsMatrix))
```

### ANN Model
```{r}
library(neuralnet)
ann1 <- neuralnet(formula = c_train_labelsMatrix ~ . , data = c_trainMatrix)
plot(ann1)

ann_results <- compute(ann1, c_testMatrix)
predicted_y <- ann_results$net.result
predicted_y_dummy <- ifelse(predicted_y >= 0.5, 1, 0)

library(gmodels)
CrossTable(x = c_train_labelsMatrix, y = predicted_y_dummy, 
           prop.chisq=FALSE)

library(caret)
annmatrix <- confusionMatrix(as.factor(c_test_labelsMatrix), as.factor(predicted_y_dummy))
```

### SVM
```{r}
library(kernlab)
#Creating SVM model (polydot)
svm_poly <- ksvm(c_train_labelsMatrix ~ ., data = c_trainMatrix,
                          kernel = "polydot")
svmpred_poly <- predict(svm_poly, c_testMatrix)
svmpred_poly <- ifelse(svmpred_poly >= 0.5, 1, 0)
#Creating polydot confusion matrix
svmmatrix_poly <- confusionMatrix(as.factor(c_test_labelsMatrix), as.factor(svmpred_poly))

#Creating SVM model (laplace)
svm_laplace <- ksvm(c_train_labelsMatrix ~ ., data = c_trainMatrix,
                          kernel = "laplacedot")
svmpred_laplace <- predict(svm_laplace, c_testMatrix)
svmpred_laplace <- ifelse(svmpred_laplace >= 0.5, 1, 0)
#Creating laplace confusion matrix
svmmatrix_laplace <- confusionMatrix(as.factor(c_test_labelsMatrix), as.factor(svmpred_laplace))

#Creating SVM model (rdfdot)
svm_rbf <- ksvm(c_train_labelsMatrix ~ ., data = c_trainMatrix,
                          kernel = "rbfdot")
svmpred_rbf <- predict(svm_rbf, c_testMatrix)
svmpred_rbf <- ifelse(svmpred_rbf >= 0.5, 1, 0)
#Creating rdfdot confusion matrix
svmmatrix_rbf <- confusionMatrix(as.factor(c_test_labelsMatrix), as.factor(svmpred_rbf))

#Finding out which SVM model worked the best
svmmatrix_poly
svmmatrix_laplace
svmmatrix_rbf
svmmatrix <- svmmatrix_rbf
```

### Decision Tree
```{r}
library("C50")
library(gmodels)

#Creating decision tree model
mod1 <- C5.0(c_train_labels ~ ., data = c_train)
plot(mod1)
summary(mod1)

#Creating prediction from decision tree model
treepred <- predict(mod1, c_test)
treematrix <- confusionMatrix(as.factor(c_test_labels), treepred)

#Creating second decision tree model
#mod2 <- C5.0(c_train_labels ~ senior_citizen + dependents_yes + tenure +
#                    multiple_lines_yes + internet_service_fiber_optic + internet_service_no +
#                    online_security_yes + tech_support_yes + streaming_tv_yes + streaming_movies_yes +
#                    contract_one_year + contract_two_year + paperless_billing_yes + 
#                    payment_method_electronic_check + monthly_charges + total_charges, data = c_train)
#plot(mod2)
#summary(mod2)

#Creating predicition from the second decision tree model
#treepred2 <- predict(mod2, telcomatrix_jan)
#treematrix2 <- confusionMatrix(as.factor(telcomatrix_jan$churn_yes), treepred2)

#Finding out which decision tree matrix worked the best
treematrix
#treematrix2
```

### Stacked Model

```{r}
#Creating combining prediction vector
stacked <- data.frame(c_test_labelsMatrix, prediction2, knn1, predicted_y_dummy, treepred, svmpred_rbf)
names(stacked) <- c("Actual", "GLM", "KNN", "ANN", "TREE", "SVM")

#Manging data
stacked$Actual <- as.factor(stacked$Actual)
stacked$ANN <- as.factor(stacked$ANN)
stacked$SVM <- as.factor(stacked$SVM)
stacked$TREE <- as.factor(ifelse(stacked$TREE == "Yes", 1, 0))

#Examining struture of dataframe
str(stacked)

#Creating test and train sets
stacked_train <- stacked[1:nrow(stacked)*3/4, ]
stacked_test  <- stacked[nrow(stacked)*3/4 + 1:nrow(stacked), ]

#Creating decision tree on the train set
dectree <- C5.0(Actual ~ ., data = stacked_train)
plot(dectree)
summary(dectree)

#Predicting the test data
dectreepred <- predict(dectree, stacked_test)
stackedmatrix <- confusionMatrix(stacked_test$Actual, dectreepred)

#Creating confusion matrix for stacked model
stackedmatrix
```

### Comparing all models

```{r}
glmmatrix$overall
knnmatrix$overall
annmatrix$overall
svmmatrix_rbf$overall
treematrix$overall
stackedmatrix$overall

accuracies <- c(glmmatrix$overall[1], knnmatrix$overall[1], annmatrix$overall[1], svmmatrix_rbf$overall[1], treematrix$overall[1], stackedmatrix$overall[1])

kappas <- c(glmmatrix$overall[2], knnmatrix$overall[2], annmatrix$overall[2], svmmatrix_rbf$overall[2], treematrix$overall[2], stackedmatrix$overall[2])

sensitivities <- c(glmmatrix$byClass[1], knnmatrix$byClass[1], annmatrix$byClass[1], svmmatrix_rbf$byClass[1], treematrix$byClass[1],stackedmatrix$byClass[1])

specificities <- c(glmmatrix$byClass[2], knnmatrix$byClass[2], annmatrix$byClass[2], svmmatrix_rbf$byClass[2], treematrix$byClass[2],stackedmatrix$byClass[2])

names <- c("GLM", "ANN", "KNN", "SVM", "TREE", "STACKED")
models <- data.frame(names, accuracies, kappas, sensitivities, specificities)

models %>% arrange(as.numeric(accuracies)) %>% mutate(names=factor(names, levels=names)) %>% ggplot(aes(x = as.factor(names), y = as.numeric(accuracies) * 100, fill = as.factor(names))) + geom_col(show.legend = FALSE) + ylim(0,100) + geom_text(aes(label = paste(round(as.numeric(accuracies) * 100, 2), "%"), vjust = -0.5)) + ylab("Accuracy (%)") + xlab("Model") + ggtitle("Model Accuracies")

models %>% arrange(as.numeric(kappas)) %>% mutate(names=factor(names, levels=names)) %>% ggplot(aes(x = as.factor(names), y = as.numeric(kappas), fill = as.factor(names))) + geom_col(show.legend = FALSE) + ylim(0,1) + geom_text(aes(label = paste(round(as.numeric(kappas), 2)), vjust = -0.5)) + ylab("Kappa") + xlab("Model") + ggtitle("Model Kappa Values")

models %>% arrange(as.numeric(sensitivities)) %>% mutate(names=factor(names, levels=names)) %>% ggplot(aes(x = as.factor(names), y = as.numeric(sensitivities) * 100, fill = as.factor(names))) + geom_col(show.legend = FALSE) + ylim(0,100) + geom_text(aes(label = paste(round(as.numeric(sensitivities) * 100, 2), "%"), vjust = -0.5)) + ylab("Sensitivity (%)") + xlab("Model") + ggtitle("Model Sensitivities")

models %>% arrange(as.numeric(specificities)) %>% mutate(names=factor(names, levels=names)) %>% ggplot(aes(x = as.factor(names), y = as.numeric(specificities) * 100, fill = as.factor(names))) + geom_col(show.legend = FALSE) + ylim(0,100) + geom_text(aes(label = paste(round(as.numeric(specificities) * 100, 2), "%"), vjust = -0.5)) + ylab("Specificity (%)") + xlab("Model") + ggtitle("Model Specificities")

library(reshape2)
modelsmelt <- melt(models ,  id.vars = 'names', variable.name = 'series')

modelsmelt %>% ggplot(aes(names, value)) + geom_bar(stat="identity", position = "dodge", aes(fill = series)) + ylim(0,1) + ggtitle("Model Comparison") + xlab("Model") + ylab("Value") + scale_fill_discrete(name = "Metrics", labels = c("Accuracy", "Kappa", "Sensitivity", "Specificity"))

modelsmelt %>% ggplot(aes(series, value)) + geom_bar(stat="identity", position = "dodge", aes(fill = names)) + ylim(0,1) + ggtitle("Model Comparison") + xlab("Metric") + ylab("Value") +  scale_fill_discrete(name = "Models") + scale_x_discrete(labels = c("Accuracy", "Kappa", "Sensitivity", "Specificity"))
```
